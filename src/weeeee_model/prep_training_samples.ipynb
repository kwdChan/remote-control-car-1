{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load \n",
    "import torch as tch\n",
    "from torch import nn\n",
    "import torchaudio as ta\n",
    "import torchaudio.transforms as tatx\n",
    "import torchaudio.functional as tafn\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "\n",
    "from train_tools import find_lr, check_with_patient, UpdatingPlotlyLines, fit_step, evaluate\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as nnfn\n",
    "\n",
    "device = tch.device(\"cuda\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_we_sample import CommonVoiceDataset, get_segment, get_middle_segment, get_random_segment, get_middle_segment_jitter, PositiveSampleSet, NegativeSampleSet, MergePosNegSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_df = pd.read_csv('temp/we_df.csv')\n",
    "we_seg_df = pd.read_csv('temp/wee_seg_16000.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ds = CommonVoiceDataset('dataset/Common Voice Corpus 1/en/', 16000)\n",
    "full_ds.use_df(full_ds.get_df('validated'))\n",
    "\n",
    "we_ds = CommonVoiceDataset('dataset/Common Voice Corpus 1/en/', 16000)\n",
    "we_ds.use_df(we_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalMaxPool1d(nn.Module):\n",
    "    def __init__(self, sz=None):\n",
    "        super().__init__()\n",
    "       \n",
    "\n",
    "    def forward(self, x): \n",
    "        inp_size = x.size()\n",
    "        return nn.functional.max_pool1d(input=x,\n",
    "                  kernel_size= (inp_size[-1]))\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, 16, stride=8), \n",
    "            nn.ReLU(), \n",
    "\n",
    "            nn.Conv1d(32, 64, 16, stride=8), \n",
    "            nn.ReLU(), \n",
    "\n",
    "            nn.Conv1d(64, 128, 8, stride=4), \n",
    "            nn.ReLU(), \n",
    "\n",
    "            nn.Conv1d(128, 256, 4, stride=2), \n",
    "            nn.ReLU(), \n",
    "            \n",
    "           \n",
    "            GlobalMaxPool1d(),\n",
    "\n",
    " \n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(), \n",
    "\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return tch.squeeze(self.conv(x))\n",
    "\n",
    "\n",
    "m = Model()#.to('cuda')\n",
    "optimiser = Adam(m.parameters(), 0.001)\n",
    "m(get_middle_segment(we_ds, we_seg_df, 7, 400)[None, ...]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for k, v in m.state_dict().items():\n",
    "    i += np.prod(v.shape)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, StackDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = NegativeSampleSet(full_ds, 400)\n",
    "pos = PositiveSampleSet(we_ds, 400, we_seg_df, 0.2) # make it 0.2 to reduce the confusion\n",
    "ds2 = MergePosNegSet(pos, neg)\n",
    "dl = DataLoader(ds2, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_lr(Model, dl, Adam, nnfn.binary_cross_entropy, starting_lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim \n",
    "from train_tools import find_lr, check_with_patient, UpdatingPlotlyLines, fit_step, evaluate, evaluate_v2\n",
    "\n",
    "def fit(\n",
    "        model: nn.Module, \n",
    "        train_dataloader: DataLoader, \n",
    "        val_dataloader:DataLoader, \n",
    "        optimiser: optim.Optimizer, \n",
    "        loss_fn, \n",
    "        epochs: int, \n",
    "        silent=True\n",
    "    ):\n",
    "    \"\"\"\n",
    "    reference implementation \n",
    "    \"\"\"\n",
    "\n",
    "    fig = UpdatingPlotlyLines('epoch', ['train_loss', 'acc'])\n",
    "    fig.display()\n",
    "    oop = check_with_patient(10)\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = fit_step(model, train_dataloader, optimiser, loss_fn, silent=silent)\n",
    "        y_pred, y = evaluate_v2(m, dl)\n",
    "\n",
    "        acc = tch.sum(y == (y_pred>0.5))/len(y)\n",
    "        \n",
    "\n",
    "        fig.append(epoch=epoch, train_loss=train_loss, acc=acc.cpu())\n",
    "\n",
    "        if oop(train_loss):\n",
    "            return fig\n",
    "\n",
    "    return fig \n",
    "\n",
    "m = Model().to('cuda')\n",
    "o = Adam(m.parameters(), lr=0.0015,)\n",
    "\n",
    "fit(m, dl, dl, o, nnfn.binary_cross_entropy, 200 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_tools import find_lr, check_with_patient, UpdatingPlotlyLines, fit_step, evaluate, evaluate_v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y = evaluate_v2(m, dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_v3(model: nn.Module, dataloader: DataLoader):\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    fp_xs = []\n",
    "    fn_xs = []\n",
    "\n",
    "    fp_ys = []\n",
    "    fn_ys = []\n",
    "\n",
    "\n",
    "\n",
    "    with tch.no_grad():\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            y_pred = out > 0.5\n",
    "\n",
    "            y = y.to(bool)\n",
    "\n",
    "            false_positive = y_pred & (~y)\n",
    "            false_negative = (~y_pred) & y\n",
    "\n",
    "            \n",
    "            fp_xs.append(x[false_positive])\n",
    "            fp_ys.append(out[false_positive])\n",
    "\n",
    "            fn_xs.append(x[false_negative])\n",
    "            fn_ys.append(out[false_negative])\n",
    "\n",
    "        \n",
    "    return tch.concat(fp_xs), tch.concat(fn_xs), tch.concat(fp_ys), tch.concat(fn_ys)\n",
    "fp, fn, fp_ys, fn_ys = evaluate_v3(m, dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fp[50].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fp[49].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fp[0].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fp[1].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fp[2].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fp[3].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fp[4].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fn[0].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fn[1].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fn[2].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fn[3].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fn[5].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(m, dl, nnfn.binary_cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tch.sum(y == (y_pred>0.5))/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tch.sum((y==1) & (y_pred>0.5))/tch.sum(y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tch.sum((y==0) & (y_pred>0.5))/tch.sum(y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tch.sum((y==1) & (y_pred<0.5))/tch.sum(y_pred<0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tch.sum((y==0) & (y_pred<0.5))/tch.sum(y_pred<0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
