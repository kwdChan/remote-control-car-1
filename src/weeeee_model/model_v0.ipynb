{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load \n",
    "import torch as tch\n",
    "from torch import nn\n",
    "import torchaudio as ta\n",
    "import torchaudio.transforms as tatx\n",
    "import torchaudio.functional as tafn\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "\n",
    "from train_tools import find_lr, check_with_patient, UpdatingPlotlyLines, fit_step, evaluate\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as nnfn\n",
    "\n",
    "device = tch.device(\"cuda\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_we_sample import CommonVoiceDataset, get_segment, get_middle_segment, get_random_segment, get_middle_segment_jitter, PositiveSampleSet, NegativeSampleSet, MergePosNegSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ds = CommonVoiceDataset('dataset/Common Voice Corpus 1/en/', 16000)\n",
    "full_df = full_ds.get_df('validated')\n",
    "full_df_shuffled = full_df.sample(len(full_df), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_val_size=50000\n",
    "neg_train_ds = CommonVoiceDataset('dataset/Common Voice Corpus 1/en/', 16000)\n",
    "neg_train_ds.use_df(full_df_shuffled.iloc[:-neg_val_size])\n",
    "\n",
    "neg_val_ds = CommonVoiceDataset('dataset/Common Voice Corpus 1/en/', 16000)\n",
    "neg_val_ds.use_df(full_df_shuffled.iloc[neg_val_size:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_df = pd.read_csv('temp/we_df.csv')\n",
    "we_seg_df = pd.read_csv('temp/wee_seg_16000.csv', index_col=0)\n",
    "\n",
    "idx = np.random.choice(len(we_df), len(we_df), replace=False)\n",
    "we_df_shuffled = we_df.iloc[idx]\n",
    "we_seg_df_shuffled = we_seg_df.iloc[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_val_size = 500\n",
    "pos_train_ds = CommonVoiceDataset('dataset/Common Voice Corpus 1/en/', 16000)\n",
    "pos_train_ds.use_df(we_df_shuffled[:-pos_val_size])\n",
    "we_seg_df_shuffled_train = we_seg_df_shuffled[:-pos_val_size]\n",
    "\n",
    "pos_val_ds = CommonVoiceDataset('dataset/Common Voice Corpus 1/en/', 16000)\n",
    "pos_val_ds.use_df(we_df_shuffled[-pos_val_size:])\n",
    "we_seg_df_shuffled_val = we_seg_df_shuffled[-pos_val_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalMaxPool1d(nn.Module):\n",
    "    def __init__(self, sz=None, squeeze=False):\n",
    "        super().__init__()\n",
    "        self.squeeze = squeeze\n",
    "    def forward(self, x): \n",
    "        inp_size = x.size()\n",
    "        out = nn.functional.max_pool1d(input=x,\n",
    "                  kernel_size= (inp_size[-1]))\n",
    "\n",
    "        if self.squeeze:\n",
    "            out = out[..., -1]\n",
    "        return out\n",
    "\n",
    "    \n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, 16, stride=8), \n",
    "            nn.ReLU(), \n",
    "\n",
    "            nn.Conv1d(32, 64, 16, stride=8), \n",
    "            nn.ReLU(), \n",
    "\n",
    "            nn.Conv1d(64, 128, 8, stride=4), \n",
    "            nn.ReLU(), \n",
    "\n",
    "            nn.Conv1d(128, 256, 4, stride=2), \n",
    "            nn.ReLU(), \n",
    "            \n",
    "           \n",
    "            GlobalMaxPool1d(squeeze=True),\n",
    "\n",
    "            #nn.Dropout(0.4),\n",
    "\n",
    "            #nn.Flatten(),\n",
    "            # nn.Linear(256, 64),\n",
    "            # nn.ReLU(), \n",
    "\n",
    "            # nn.Linear(64, 1),\n",
    "            # nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return tch.squeeze(self.conv(x))\n",
    "\n",
    "\n",
    "m = Model()#.to('cuda')\n",
    "optimiser = Adam(m.parameters(), 0.001)\n",
    "m(tch.rand(1, 1, 120000)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for k, v in m.state_dict().items():\n",
    "    i += np.prod(v.shape)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dl(pos_ds, neg_ds, we_seg_df): \n",
    "    pos_ds = PositiveSampleSet(pos_ds, 400, we_seg_df, 0.2) # make it 0.2 to reduce the confusion\n",
    "    neg_ds = NegativeSampleSet(neg_ds, 400)\n",
    "    ds = MergePosNegSet(pos_ds, neg_ds)\n",
    "\n",
    "    dl = DataLoader(ds, batch_size=64, shuffle=True)\n",
    "    return dl\n",
    "train_dl = get_dl(pos_train_ds, neg_train_ds, we_seg_df_shuffled_train)\n",
    "val_dl = get_dl(pos_val_ds, neg_val_ds, we_seg_df_shuffled_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preload the cache\n",
    "for i, (x, y) in enumerate(train_dl):\n",
    "    x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preload the cache\n",
    "for x, y in val_dl: \n",
    "    x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_lr(Model, train_dl, Adam, nnfn.binary_cross_entropy, starting_lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim \n",
    "from train_tools import find_lr, check_with_patient, UpdatingPlotlyLines, fit_step, evaluate, evaluate_v2\n",
    "from nb_tools import show_global_variables\n",
    "@show_global_variables\n",
    "def fit(\n",
    "        model: nn.Module, \n",
    "        train_dataloader: DataLoader, \n",
    "        val_dataloader:DataLoader, \n",
    "        optimiser: optim.Optimizer, \n",
    "        loss_fn, \n",
    "        epochs: int, \n",
    "        silent=True\n",
    "    ):\n",
    "    \"\"\"\n",
    "    reference implementation \n",
    "    \"\"\"\n",
    "    \n",
    "    fig = UpdatingPlotlyLines('epoch', ['train_loss', 'eval_loss', 'acc'])\n",
    "    fig.display()\n",
    "    oop = check_with_patient(15)\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = fit_step(model, train_dataloader, optimiser, loss_fn, silent=silent)\n",
    "        y_pred, y = evaluate_v2(model, val_dataloader)\n",
    "\n",
    "        eval_loss = loss_fn(y_pred, y)\n",
    "        acc = tch.sum(y == (y_pred>0.5))/len(y)\n",
    "        \n",
    "\n",
    "        fig.append(epoch=epoch, train_loss=train_loss, eval_loss=eval_loss.cpu(), acc=acc.cpu())\n",
    "\n",
    "        if oop(eval_loss):\n",
    "            return fig\n",
    "\n",
    "    return fig \n",
    "\n",
    "m = Model().to('cuda')\n",
    "o = Adam(m.parameters(), lr=0.0015,)\n",
    "\n",
    "fit(m, train_dl, val_dl, o, nnfn.binary_cross_entropy, 200 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_tools import find_lr, check_with_patient, UpdatingPlotlyLines, fit_step, evaluate, evaluate_v2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_v3(model: nn.Module, dataloader: DataLoader):\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    fp_xs = []\n",
    "    fn_xs = []\n",
    "\n",
    "    fp_ys = []\n",
    "    fn_ys = []\n",
    "\n",
    "\n",
    "\n",
    "    with tch.no_grad():\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            y_pred = out > 0.5\n",
    "\n",
    "            y = y.to(bool)\n",
    "\n",
    "            false_positive = y_pred & (~y)\n",
    "            false_negative = (~y_pred) & y\n",
    "\n",
    "            \n",
    "            fp_xs.append(x[false_positive])\n",
    "            fp_ys.append(out[false_positive])\n",
    "\n",
    "            fn_xs.append(x[false_negative])\n",
    "            fn_ys.append(out[false_negative])\n",
    "\n",
    "        \n",
    "    return tch.concat(fp_xs), tch.concat(fn_xs), tch.concat(fp_ys), tch.concat(fn_ys)\n",
    "fp, fn, fp_ys, fn_ys = evaluate_v3(m, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fp[0].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fp[2].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fp[1].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fp[3].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fp[2].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fp[3].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fp[4].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fn[0].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fn[1].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fn[2].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fn[2:3].clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = Adam([x], lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for _ in range(10):\n",
    "    l = 1-m(x)\n",
    "    l.backward()\n",
    "    o.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m(fn[2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line((fn[2:3].cpu()-x.clone().detach().cpu())[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line((x.clone().detach().cpu())[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(y=[(fn[2:3].cpu())[0,0], (x.clone().detach().cpu())[0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio((fn[2:3].cpu()-x.clone().detach().cpu())[0], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 1-m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(x[0, 0].clone().detach().cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fn[2].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tatx.Spectrogram(fn[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fn[5].cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(m, dl, nnfn.binary_cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tch.sum(y == (y_pred>0.5))/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tch.sum((y==1) & (y_pred>0.5))/tch.sum(y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tch.sum((y==0) & (y_pred>0.5))/tch.sum(y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tch.sum((y==1) & (y_pred<0.5))/tch.sum(y_pred<0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tch.sum((y==0) & (y_pred<0.5))/tch.sum(y_pred<0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_program = tch.onnx.dynamo_export(m, tch.rand(1, 1, 6400).to('cuda'))\n",
    "onnx_program.save('model_v0.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig, fs = ta.load('./dataset/weeeee.mp3')\n",
    "sig = tafn.resample(sig[0], fs, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sig[23000:23000+6400], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[None, None, :].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wecognition_pipeline import RunModel \n",
    "\n",
    " \n",
    "\n",
    "m = RunModel('model_v0.onnx', 16000, 6400)\n",
    "x = m.striding(sig.numpy(), 16000, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[None, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.model(x[None,0, None, ])\n",
    "ys = []\n",
    "for x_ in x:\n",
    "    ys.append(m.model(x_[None, None, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sig, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sig.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
