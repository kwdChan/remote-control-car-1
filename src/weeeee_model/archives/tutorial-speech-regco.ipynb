{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/audio/stable/tutorials/speech_recognition_pipeline_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "from torchaudio.utils import download_asset\n",
    "\n",
    "SPEECH_FILE = download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample Rate:\", bundle.sample_rate)\n",
    "\n",
    "print(\"Labels:\", bundle.get_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bundle.get_model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate = torchaudio.load(SPEECH_FILE)\n",
    "waveform = waveform.to(device)\n",
    "\n",
    "waveform = torchaudio.functional.resample(waveform, sample_rate, bundle.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "     with torch.inference_mode():\n",
    "       features, _ = model.extract_features(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(features), 1, figsize=(16, 4.3 * len(features)))\n",
    "for i, feats in enumerate(features):\n",
    "    ax[i].imshow(feats[0].cpu(), interpolation=\"nearest\")\n",
    "    ax[i].set_title(f\"Feature from transformer layer {i+1}\")\n",
    "    ax[i].set_xlabel(\"Feature dimension\")\n",
    "    ax[i].set_ylabel(\"Frame (time-axis)\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    emission, _ = model(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(emission[0].cpu().T, interpolation=\"nearest\")\n",
    "plt.title(\"Classification result\")\n",
    "plt.xlabel(\"Frame (time-axis)\")\n",
    "plt.ylabel(\"Class\")\n",
    "plt.tight_layout()\n",
    "print(\"Class labels:\", bundle.get_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyCTCDecoder(torch.nn.Module):\n",
    "    def __init__(self, labels, blank=0):\n",
    "        super().__init__()\n",
    "        self.labels = labels\n",
    "        self.blank = blank\n",
    "\n",
    "    def forward(self, emission: torch.Tensor) -> str:\n",
    "        \"\"\"Given a sequence emission over labels, get the best path string\n",
    "        Args:\n",
    "          emission (Tensor): Logit tensors. Shape `[num_seq, num_label]`.\n",
    "\n",
    "        Returns:\n",
    "          str: The resulting transcript\n",
    "        \"\"\"\n",
    "        indices = torch.argmax(emission, dim=-1)  # [num_seq,]\n",
    "        indices = torch.unique_consecutive(indices, dim=-1)\n",
    "        indices = [i for i in indices if i != self.blank]\n",
    "        return \"\".join([self.labels[i] for i in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = GreedyCTCDecoder(labels=bundle.get_labels())\n",
    "transcript = decoder(emission[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcript)\n",
    "IPython.display.Audio(SPEECH_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique_consecutive(torch.argmax(emission, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(emission, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
