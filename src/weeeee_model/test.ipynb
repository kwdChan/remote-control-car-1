{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "sys.path += ['..']\n",
    "from data_collection.data_collection import Logger\n",
    "import plotly.express as px\n",
    "import scipy.signal as ss\n",
    "\n",
    "import torchaudio as ta\n",
    "import torch as tch\n",
    "tafn = ta.functional\n",
    "tatx = ta.transforms\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import Audio\n",
    "from nb_tools import *\n",
    "from scipy.fft import fft, ifft, fftfreq\n",
    "from functools import partial\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;1mGlobal variables of <function '\u001b[1;32;1mload_wav\u001b[0m'>: \u001b[0m\n",
      "\u001b[1;32;1mPath\u001b[0m                                                \u001b[1;32;1m<class 'type'>\u001b[0m\n",
      "\u001b[1;37;1mta\u001b[0m                                                  \u001b[1;37;1m<class 'module'>\u001b[0m\n",
      "\u001b[1;37;1mfilter\u001b[0m                                              \u001b[1;37;1m<class 'type'>\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@show_global_variables\n",
    "def load_wav(path):\n",
    "    path = Path(path)\n",
    "\n",
    "    data = {}\n",
    "    for f in filter(lambda f:f.suffix=='.wav', path.iterdir()):\n",
    "        sig, fs = ta.load(f)\n",
    "        data[f.stem] = sig\n",
    "\n",
    "    return data\n",
    "\n",
    "rate=16000\n",
    "Audio = partial(Audio, rate=16000)\n",
    "\n",
    "data = load_wav('../../log/audio_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wecognition_pipeline import RunModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RunModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
